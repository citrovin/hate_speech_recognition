{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Bonusaufgabe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Aufgabenstellung\n",
    "Gerade in den letzten Jahren wurde immer mehr deutlich, was f√ºr eine Reichweite Kommentare und Beitr√§ge im Internet haben k√∂nnen. Der Gro√üteil der Meinungs√§u√üerung findet online statt. Dadurch steigt jedoch auch die Anzahl an unangemessen und sch√§dlichen Inhalten, die von Mobbing bis hin zu Shit-Storms ausarten k√∂nnen.\n",
    "Ihre Aufgabe bei dieser Herausforderung wird es sein, die Rolle einer ‚ÄûContent-Polizei\" zu √ºbernehmen. Um ein zivilisiertes und ordnungsgem√§√ües Verhalten auf einer imagin√§ren Social Media-Plattform zu gew√§hrleisten, m√ºssen Sie alle unerw√ºnschten Inhalte aussortieren. Zu diesem Zweck wird Ihnen ein Trainingsset mit anonymisierten Benutzerbeitr√§gen zur Verf√ºgung gestellt, die jeweils als angemessen oder nicht angemessen gekennzeichnet sind. Verwenden Sie diese Trainingsmenge, um ein Modell zu entwickeln, das Beitr√§ge in angemessene und unangemessene klassifizieren kann.\n",
    "\n",
    "\n",
    "### Data\n",
    "Die Datei train.tsv umfasst Ihre Trainingsdaten. Jede Zeile enth√§lt den Text eines Beitrags und ein Label, getrennt durch ein TAB-Zeichen. Erw√§hnungen von Benutzernamen innerhalb des Textes wurden durch ‚Äû@USER\" und URLs durch ‚Äû{{URL}}\" ersetzt. Die Klassenlabels sind ‚ÄûOK\" f√ºr geeignete Inhalte und ‚ÄûNG\" (‚Äûnot good‚Äú) f√ºr unangemessene Inhalte.\n",
    "Die Datei test.tsv.dist enth√§lt die Testdaten, die am Ende zur Bewertung Ihres Modells verwendet werden. Sie enth√§lt keine Klassenlabels.\n",
    "\n",
    "### Formalit√§ten\n",
    "(1) Verwenden Sie bestehende Methoden des maschinellen Lernens f√ºr die Klassifizierung.\n",
    "(2) Sie k√∂nnen existierende Tools (e.g. Weka1), Libraries (e.g. Sklearn2, NLTK3, Keras4) und Programmiersprachen (vorrangig Python5; R6 auch m√∂glich, falls bereits erlernt) verwenden.\n",
    "\n",
    "### Abgabe\n",
    "Die Abgabe ist bis zum 30. Januar 2022, 23:59 Uhr √ºber Ilias in dem Ordner Bonusabgabe m√∂glich. Einreichungen, die nach der Frist eingehen, werden von der Bewertung ausgeschlossen. Die folgenden Unterlagen m√ºssen eingereicht werden:\n",
    "1. Eine Kopie der Datei test.tsv.dist mit den von Ihnen vorhergesagten Klassenlabels (die Reihenfolge der Zeilen muss der urspr√ºnglichen test.tsv.dist entsprechen; verwenden Sie \\OK\" und \\NG\" als Klassenlabels).\n",
    "2. Programmcode, falls verwendet. Wenn Weka oder ein anderes Tool verwendet wurde, senden Sie bitte Screenshots, die die verwendeten Funktionen/Parameter/etc. veranschaulichen.\n",
    "3. PDF-Datei mit:\n",
    "‚Ä¢ Vollst√§ndigem Namen, E-Mail-Adresse und Matrikelnummer.\n",
    "‚Ä¢ Kurzer Beschreibung des Ansatzes f√ºr die Klassifizierung (4-5 S√§tze)\n",
    "‚Ä¢ Informationen zu den Bewertungskriterien und dem Training/Test-Split, den Sie bei\n",
    "der Erarbeitung verwendet haben.\n",
    "Bitte laden Sie alle oben genannten Informationen/Daten in einem ZIP-Archiv von angemessener Gr√∂√üe (maximal einige MB) hoch und benennen Sie dieses wie folgt: u-K√ºrzel.zip. Abgaben, die formal nicht korrekt sind (z.B. inkorrekte Dateinamensgebung, falsches Dateiformat oder fehlende Dateien in der Abgabe), werden nicht bewertet.\n",
    "\n",
    "### Ergebnisse Auswertung\n",
    "Die von Ihnen vorhergesagten Labels f√ºr die Eintr√§ge in test.tsv.dist werden mit Hilfe eines F1 Score bewertet.\n",
    "### Bonuspunkte\n",
    "Wenn Ihre Vorhersagen, die anhand der Testdaten ausgewertet werden, einen Makro-F1-Wert von 0,85 erreichen, erhalten Sie einen Bonuspunkt, bei 0,90 zwei Bonuspunkte und bei 0,95 drei Bonuspunkte auf Ihre bestandene Pr√ºfung. Die beste Abgabe von allen erh√§lt zus√§tzlich noch einmal drei Bonuspunkte."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                                                    text label\n1427          Thanks for that text... I found that hoe..    NG\n3910   @USER someone on Facebook made a status defend...    NG\n4024                      Lowkey you're still my bitch üòè    NG\n6787   Nothing says teabagger like a millionaire comp...    OK\n11144        That pussy best be shaved for the holidays!    NG\n...                                                  ...   ...\n5679   RT @USER: ‚Äú@USER: Last night was cool until ni...    NG\n12099                            @USER that funky monkey    OK\n2832         @USER @USER #icanhashtaghoweveriwant #bitch    NG\n10744                   Happy birthday fag @USER love ya    NG\n18587  Smuggled letter by Gaza tunnel digger details ...    OK\n\n[14946 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1427</th>\n      <td>Thanks for that text... I found that hoe..</td>\n      <td>NG</td>\n    </tr>\n    <tr>\n      <th>3910</th>\n      <td>@USER someone on Facebook made a status defend...</td>\n      <td>NG</td>\n    </tr>\n    <tr>\n      <th>4024</th>\n      <td>Lowkey you're still my bitch üòè</td>\n      <td>NG</td>\n    </tr>\n    <tr>\n      <th>6787</th>\n      <td>Nothing says teabagger like a millionaire comp...</td>\n      <td>OK</td>\n    </tr>\n    <tr>\n      <th>11144</th>\n      <td>That pussy best be shaved for the holidays!</td>\n      <td>NG</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>5679</th>\n      <td>RT @USER: ‚Äú@USER: Last night was cool until ni...</td>\n      <td>NG</td>\n    </tr>\n    <tr>\n      <th>12099</th>\n      <td>@USER that funky monkey</td>\n      <td>OK</td>\n    </tr>\n    <tr>\n      <th>2832</th>\n      <td>@USER @USER #icanhashtaghoweveriwant #bitch</td>\n      <td>NG</td>\n    </tr>\n    <tr>\n      <th>10744</th>\n      <td>Happy birthday fag @USER love ya</td>\n      <td>NG</td>\n    </tr>\n    <tr>\n      <th>18587</th>\n      <td>Smuggled letter by Gaza tunnel digger details ...</td>\n      <td>OK</td>\n    </tr>\n  </tbody>\n</table>\n<p>14946 rows √ó 2 columns</p>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('./data/train.tsv', sep='\\t')\n",
    "data_test = pd.read_csv('./data/test.tsv.dist', sep='\\t')\n",
    "\n",
    "data = pd.DataFrame(data)\n",
    "\n",
    "# training data 80% of original data\n",
    "df_train= data.sample(frac=0.8, random_state=42)\n",
    "# validation data 20% of original data\n",
    "df_val = data.drop(df_train.index)\n",
    "\n",
    "\n",
    "df_test = pd.DataFrame(data_test)\n",
    "#df_val\n",
    "df_train\n",
    "#df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Analyse Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "NG    15352\nOK     3330\nName: label, dtype: int64"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([15352,  3330])"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "occ=df_train['label'].value_counts().values # => np.array\n",
    "occ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Percentage of occurrences (NG):  0.8217535595760626 \n",
      " Percentage of occurrences (OK):  0.17824644042393747\n"
     ]
    }
   ],
   "source": [
    "sum=occ[0]+occ[1]\n",
    "\n",
    "print(' Percentage of occurrences (NG): ', (occ[0]/sum), '\\n',\n",
    "      'Percentage of occurrences (OK): ', (occ[1]/sum))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Modell: Pre-Trained Bert from Hugingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'BertTokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/jz/9tl5trdj6fs3_b0t0hktzhg40000gn/T/ipykernel_10769/125795080.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mtokenizer\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mBertTokenizer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfrom_pretrained\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'bert-base-uncased'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m: name 'BertTokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "tokenizer=BertTokenizer.from_pretrained('bert-base-uncased')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}